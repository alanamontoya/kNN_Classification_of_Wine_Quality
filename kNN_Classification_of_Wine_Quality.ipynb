{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf995fe",
   "metadata": {},
   "source": [
    "_Import the `pandas`, `numpy`, `train_test_split`, `LogisticRegression`, `accuracy_score`, `confusion_matrix`, `KNeighborsClassifier`, and `pyplot`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb909c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b2718",
   "metadata": {},
   "source": [
    "## Problem 1:\n",
    "An automated answer-rating site marks each post in a community forum website as “good” or “bad” based on the quality of the post. The `quality` CSV file, contains the various types of quality as measured by the tool. Following are the type of qualities that the dataset contains:\n",
    "\n",
    "i. `num_words`: number of words in the post\n",
    "\n",
    "ii. `num_characters`: number of characters in the post\n",
    "\n",
    "iii. `num_misspelled`: number of misspelled words\n",
    "\n",
    "iv. `bin_end_qmark`: if the post ends with a question mark\n",
    "\n",
    "v. `num_interrogative`: number of interrogative words in the post\n",
    "\n",
    "vi. `bin_start_small`: if the answer starts with a lowercase letter. (‘1’ means yes, otherwise no)\n",
    "\n",
    "vii. `num_sentences`: number of sentences per post\n",
    "\n",
    "viii. `num_punctuations`: number of punctuation symbols in the post\n",
    "\n",
    "ix. `label`: the label of the post (‘G’ for good and ‘B’ for bad) as determined by the tool.\n",
    "\n",
    "Create a logistic regression model to predict the class label from the first eight attributes of the question set. Then try doing the same using two different subsets (your choice) of those eight attributes. Report the accuracies of each of these three models. For the two subsets that you use, provide some justification (why you chose those features in a given subset). As we discussed in the class, it's useful to report not just a single accuracy number for a given model, but either an average accuracy over many runs or a distribution of accuracies over those runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c6db5",
   "metadata": {},
   "source": [
    "_First we need to load in the `quality` dataset:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1729d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = pd.read_csv('quality.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5938319d",
   "metadata": {},
   "source": [
    "_Prior to building our models, we can change `label` (indicating whether a post was good (`G`) or bad (`B`)) from a string categorical type to a number categorical type. This allows us to transform this variable to be used as a binomial distribution which can then be modeled using logistic regression. We can assign them as follows:_\n",
    "> _`G` (good)   :   0_\n",
    "\n",
    "> _`B`  (bad)   :   1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d202d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality[\"label\"] = np.where(df_quality[\"label\"] ==  \"B\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf347db",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### _Create a logistic regression model to predict the class label from the first eight attributes_\n",
    "\n",
    "_First we can seperate the variables into features and label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7d9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = df_quality.drop(\"S.No.\", axis = 1).drop(\"label\", axis = 1)\n",
    "label = df_quality[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28567556",
   "metadata": {},
   "source": [
    "_Next we can split the data into 70% training and 30% testing. Note that `X` represents the features and `y` represents the label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56261a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, label, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13687efd",
   "metadata": {},
   "source": [
    "_Now we can fit a logistic regression model using `X_train1` as the training features and `y_train1` as the training label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f84ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression(max_iter = 10000)\n",
    "model1 = logit_model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e07ce",
   "metadata": {},
   "source": [
    "_Then we can use this trained model to make predictions for `label` using `X_test1` as the test data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4784744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db20ca",
   "metadata": {},
   "source": [
    "_Then we can use these predictions (`pred1`) and compare them against the actual values (`y_test1`) to determine the accuracy of this model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130ddd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test1, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a9b03",
   "metadata": {},
   "source": [
    "_However, it is more useful to get an average accuracy. So, we can build a function to do this. This function will take in as an input `n` number of times to iterate through the process (spliting the data, training the model, making predictions, and finding the accuracy), `features` to represent which variables to be included as features, and `labels` to indicate which variable to be included as the label. Having the second two as inputs allows this function to become more versitile so that we can use it for the next two parts._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fffcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_accuracy(n, features, labels):\n",
    "    tot = 0\n",
    "    for i in range(0, n):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.30)\n",
    "        logit_model.fit(X_train, y_train)\n",
    "        pred = logit_model.predict(X_test)\n",
    "        tot = tot + accuracy_score(y_test, pred)\n",
    "    return(tot/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190efa8",
   "metadata": {},
   "source": [
    "_Using this function, we can then find the average accuracy of the model for 100 iterations given the features and label indicated above (`features1` and `label`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a29102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455555555555555"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_accuracy(100, features1, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a8beb",
   "metadata": {},
   "source": [
    "_Hence, the number above represents the average accuracy of the logistic regression model that predicts the class label from the first eight attributes._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52051ef1",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### _Create a logistic regression model to predict the class label from the spelling, captilization, and grammar,  attributes_\n",
    "\n",
    "_When looking at the eight attributes, I noticed that they can be categorized based on different aspects. One such category that can be made could include `num_misspelled`, `bin_start_small`, and `num_punctuations`. These variables all relatively relate to how well a user knows these basic English structures or whether they cared to include them. Hence, these three variables may be useful to model the quality of a post._\n",
    "\n",
    "_First we can assign these three variables as features. Since the label will be the same as above, we do not need to recreate this variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2ae53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = df_quality.drop(\"S.No.\", axis = 1).drop(\"num_words\", axis = 1).drop(\"num_characters\", axis = 1).drop(\"bin_end_qmark\", axis = 1).drop(\"num_interrogative\", axis = 1).drop(\"num_sentences\", axis = 1).drop(\"label\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace800cb",
   "metadata": {},
   "source": [
    "_Next we can split the data into 70% training and 30% testing. Note that `X` represents the features and `y` represents the label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f810f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, label, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60201b9",
   "metadata": {},
   "source": [
    "_Now we can fit a logistic regression model using `X_train2` as the training features and `y_train2` as the training label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c37286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = logit_model.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5db129",
   "metadata": {},
   "source": [
    "_Then we can use this trained model to make predictions for `label` using `X_test2` as the test data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b64e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6e815",
   "metadata": {},
   "source": [
    "_Then we can use these predictions (`pred2`) and compare them against the actual values (`y_test2`) to determine the accuracy of this model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fa105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec6ae0",
   "metadata": {},
   "source": [
    "_Again, since it is more useful to get an average accuracy of this model, we can use the `get_avg_accuracy` function we created previously to find the average accuracy of the model for 100 iterations given the features and label indicated above (`features2` and `label`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff402bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4388888888888887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_accuracy(100, features2, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46764f34",
   "metadata": {},
   "source": [
    "_From this average accuracy, we can see that the first model made from all eight attributes performed better than this second model. This means that these three attributes (`num_misspelled`, `bin_start_small`, and `num_punctuations`) are not very good at predicting the quality of posts (when modeled together)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1967f2ee",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### _Create a logistic regression model to predict the class label from attributes implying a question_\n",
    "\n",
    "_Another category that could be made from the eight attribites is those that pertain to questions. Two variables that relate to this are `bin_end_qmark` and `num_interrogative`. Building a model based on these attributes and then measuring its accuracy could examine how well the automated answer-rating site predicts the quality of posts when questions are included._\n",
    "\n",
    "_First we can assign these three variables as features. Since label will be the same as above, we do not need to recreate this variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea9db12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = df_quality.drop(\"S.No.\", axis = 1).drop(\"num_words\", axis = 1).drop(\"num_characters\", axis = 1).drop(\"num_misspelled\", axis = 1).drop(\"bin_start_small\", axis = 1).drop(\"num_sentences\", axis = 1).drop(\"num_punctuations\", axis = 1).drop(\"label\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aecaec1",
   "metadata": {},
   "source": [
    "_Next we can split the data into 70% training and 30% testing. Note that `X` represents the features and `y` represents the label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811182e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(features3, label, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00586a",
   "metadata": {},
   "source": [
    "_Now we can fit a logistic regression model using `X_train3` as the training features and `y_train3` as the training label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1719bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = logit_model.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0300a3",
   "metadata": {},
   "source": [
    "_Then we can use this trained model to make predictions for label using `X_test3` as the test data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "865a9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = model3.predict(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c6f24",
   "metadata": {},
   "source": [
    "_Then we can use these predictions (`pred3`) and compare them against the actual values (`y_test3`) to determine the accuracy of this model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d7cbfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test3, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82374cf",
   "metadata": {},
   "source": [
    "_Again, since it is more useful to get an average accuracy of this model, we can use the `get_avg_accuracy` function we created previously to find the average accuracy of the model for 100 iterations given the features and label indicated above (`features3` and `label`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ca7a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42777777777777787"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_accuracy(100, features3, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cedbc",
   "metadata": {},
   "source": [
    "_From this average accuracy, we can see that the first model made from all eight attributes performed better than this third model and that the second and third model perform about the same. This means that these two attributes (`bin_end_qmark` and `num_interrogative`) are not very good at predicting the quality of posts (when modeled together)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84ba13",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "## Problem 2:\n",
    "\n",
    "Download the `wine` dataset. It contains information about a number of wines -- their characteristics (features) and if it's considered high quality or not (1 or 0). First, do some experiments (trial-and-error) to figure out a good subset of features to use for learning wine quality (last column). Report these features.\n",
    "\n",
    "Then, use 70% data for training to build a kNN classifier with different values of k ranging from 2 to 10. Plot your accuracies with each of these. In other words, your final result will be a line chart with k on the x-axis and accuracy on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39244b",
   "metadata": {},
   "source": [
    "_First we need to load in the `wine` dataset:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a2752d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbbb646",
   "metadata": {},
   "source": [
    "_Prior to building our models, we can change `color` (indicating whether a wine was `red` or `white`) from a string categorical type to a number categorical type. We can assign them as follows:_\n",
    "\n",
    "> _white : 0_\n",
    "\n",
    "> _red : 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c7a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine[\"color\"] = np.where(df_wine[\"color\"] ==  \"red\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e78493",
   "metadata": {},
   "source": [
    "_To figure out a good subset of features to use for learning whether a wine is of high quality, I created simple logistic models for each of the attributes and measured their average accuracy. They all had an average accuracy of predicting `high_quality` of about 0.8 but with `quality` having an average accuracy of 1.0. The `quality` feature producing a perfect accuracy makes sense since `high_quality` is determined by applying a threshold to `quality`. So while a simple logictic model with simply `quality` being used as the only feature would produce perfect accuracy, it is trivial and not very insightful. Hence, we can instead choose a subset of features that do not include `quality`, such as `fixed_acidity`, `volatile_acidity`, and `citric_acid`._\n",
    "\n",
    "_So, we can assign these three as the features to use in our model and `high_quality` as the label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfe4c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "features4 = df_wine.drop(\"high_quality\", axis = 1).drop(\"residual_sugar\", axis = 1).drop(\"chlorides\", axis = 1).drop(\"free_sulfur_dioxide\", axis = 1).drop(\"total_sulfur_dioxide\", axis = 1).drop(\"density\", axis = 1).drop(\"pH\", axis = 1).drop(\"sulphates\", axis = 1).drop(\"alcohol\", axis = 1).drop(\"quality\", axis = 1).drop(\"color\", axis = 1).drop(\"is_red\", axis = 1)\n",
    "label2 = df_wine[\"high_quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7da36e",
   "metadata": {},
   "source": [
    "_Next we can split the data into 70% training and 30% testing. Note that `X` represents the features and `y` represents the label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1678579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(features4, label2, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fa1d9",
   "metadata": {},
   "source": [
    "_Now we can build a kNN classifier with different values of `k` ranging from 2 to 10 and later graph the accuracies for each value of `k`. So, first we should create a list to keep track of the values of `k` and another list to track the accuracies at each value of `k`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a1dde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_val = list(range(2,11))\n",
    "accuracies = list(range(2,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94698b",
   "metadata": {},
   "source": [
    "> _Note: __[this](https://stackoverflow.com/questions/10712002/create-an-empty-list-in-python-with-certain-size)__ source was used to understand the `range()` function._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634cbea6",
   "metadata": {},
   "source": [
    "Then we can run through each value of `k` from 2 to 10 and track the accuracies for each of these k-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39429bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in range(2,11):\n",
    "    k_val[i] = k\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train4, y_train4)\n",
    "    pred_knn = knn.predict(X_test4)\n",
    "    accuracies[i] = accuracy_score(y_test4, pred_knn)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b232430",
   "metadata": {},
   "source": [
    "_Next we can combine these values of `k` and their corresponding accuracies into a dataframe that can be used to visually plot the results._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55b75f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k_val</th>\n",
       "      <th>accuracies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.772821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.790256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.804615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.789231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.809744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.801026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.808718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k_val  accuracies\n",
       "0      2    0.807692\n",
       "1      3    0.772821\n",
       "2      4    0.790256\n",
       "3      5    0.782051\n",
       "4      6    0.804615\n",
       "5      7    0.789231\n",
       "6      8    0.809744\n",
       "7      9    0.801026\n",
       "8     10    0.808718"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'k_val' : k_val, 'accuracies' : accuracies}\n",
    "df_accuracies = pd.DataFrame(data)\n",
    "df_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6de12",
   "metadata": {},
   "source": [
    "_Now we can plot this dataframe to see how the accuracy of our kNN classifier model varies as `k` ranges from 2 to 10._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "946ead1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'kNN Classifier Model Accuracies')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_accuracies.plot(x = \"k_val\", y = \"accuracies\", kind = \"line\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"k Value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"kNN Classifier Model Accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276a832",
   "metadata": {},
   "source": [
    "> _Note: __[this](https://stackabuse.com/how-to-set-axis-range-xlim-ylim-in-matplotlib/)__ source was used to determine how to change the axis boundaries._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
